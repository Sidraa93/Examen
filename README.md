# **Projet Collaboratif : Pipeline de Classification et Dockerisation**

## **Introduction**

Ce projet est une simulation d'un environnement collaboratif o√π plusieurs d√©veloppeurs travaillent ensemble pour construire un pipeline de machine learning complet. L'objectif est de couvrir toutes les √©tapes d'un projet machine learning, de la g√©n√©ration des donn√©es jusqu'√† leur d√©ploiement dans un conteneur Docker.  
Chaque membre contribue en d√©veloppant une fonctionnalit√© dans une branche d√©di√©e.

---

## **Structure et Objectifs**

### **Objectifs du projet**
1. G√©n√©rer des donn√©es synth√©tiques pour simuler un probl√®me de classification.
2. D√©velopper, entra√Æner et optimiser des mod√®les de classification.
3. √âvaluer les performances des mod√®les √† l'aide de techniques avanc√©es comme la validation crois√©e.
4. Impl√©menter un script de pr√©diction bas√© sur les mod√®les entra√Æn√©s.
5. Dockeriser le projet pour faciliter le partage et le d√©ploiement.

### **Architecture des branches**
- **`main` :** Branche principale contenant toute la version du projet.
- **`data_generation` :** G√©n√©ration des donn√©es.
- **`classification` :** D√©veloppement des mod√®les et √©valuation.
- **`prediction` :** Chargement des mod√®les pour effectuer des pr√©dictions.
- **`docker_integration` :** Contient les fichiers Docker et docker-compose.

---

## **Description des Donn√©es**

Les donn√©es utilis√©es dans ce projet sont g√©n√©r√©es gr√¢ce √† la biblioth√®que `scikit-learn`.  
- **Nombre d'√©chantillons :** 10,000  
- **Nombre de features :** 20  
- **Classes :** 3  
- **Proportions des donn√©es :**  
  - **70 %** pour l'entra√Ænement  
  - **20 %** pour le test  
  - **10 %** pour la validation  

Les donn√©es sont export√©es dans un fichier nomm√© `synthetic_data.csv` et utilis√©es pour entra√Æner diff√©rents mod√®les de classification.

---

## **D√©marche M√©thodologique**

### **√âtapes Suivies :**

1. **G√©n√©ration et Visualisation des Donn√©es :**
   - Cr√©ation de donn√©es synth√©tiques √©quilibr√©es.
   - Analyse des param√®tres comme `n_informative`, `class_sep`, et `n_clusters_per_class`.

2. **Entra√Ænement des Mod√®les :**
   - Mod√®les test√©s :
     - Random Forest
     - R√©gression Logistique
     - SVM
   - Optimisation des hyperparam√®tres √† l'aide de `GridSearchCV`.

3. **√âvaluation :**
   - M√©triques utilis√©es : Pr√©cision, rappel, F1-score.
   - Matrice de confusion pour visualiser les erreurs.
   - Validation crois√©e (5-fold) pour √©valuer la robustesse des mod√®les.

4. **Pr√©diction :**
   - Script `predict_classification.py` pour effectuer des pr√©dictions sur les donn√©es de validation.
   - √âvaluation des pr√©dictions et affichage des performances.

5. **Dockerisation :**
   - Le projet est dockeris√© pour garantir une portabilit√© totale.  
   - Fichiers : 
     - `Dockerfile` : Cr√©e une image Docker pour le projet.
     - `docker-compose.yml` : Orchestration des conteneurs.

---

## **R√©sultats**

### **Performance des Mod√®les :**


### **Visualisation :**
- **Matrice de Confusion :** Permet de visualiser les erreurs de classification.

---

## **Structure du Projet**

### **Organisation des Fichiers :**

```
.
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Visualisation_donn√©es.ipynb   # Visualisation des donn√©es g√©n√©r√©es
‚îú‚îÄ‚îÄ train_classifier.py               # G√©n√©ration, entra√Ænement et √©valuation des mod√®les
‚îú‚îÄ‚îÄ predict_classification.py         # Pr√©diction et √©valuation sur les donn√©es de validation
‚îú‚îÄ‚îÄ synthetic_data.csv                # Donn√©es g√©n√©r√©es (non suivies par Git)
‚îú‚îÄ‚îÄ Dockerfile                        # Fichier Docker pour le projet
‚îú‚îÄ‚îÄ docker-compose.yml                # Configuration des conteneurs Docker
‚îî‚îÄ‚îÄ README.md                         # Documentation du projet
```

---

## **Utilisation du Projet**

### **1. Lancer le Projet :**

1. **Cloner le projet :**
   ```bash
   git clone git@github.com:<ton_repo>/classification_project.git
   cd classification_project
   ```

2. **Lancer les scripts :**
   - G√©n√©ration et entra√Ænement :  
     ```bash
     python train_classifier.py
     ```
   - Pr√©diction :  
     ```bash
     python predict_classification.py
     ```

### **2. Dockerisation :**

1. **Construire l'image Docker :**
   ```bash
   docker build -t classification_project .
   ```

2. **Ex√©cuter le conteneur Docker :**
   ```bash
   docker run -it --rm classification_project
   ```

3. **Avec Docker Compose :**
   - Lancer :  
     ```bash
     docker-compose up
     ```
   - Arr√™ter :  
     ```bash
     docker-compose down
     ```

---

## **Limites et Am√©liorations**

### **Limites :**
- Les donn√©es utilis√©es sont synth√©tiques et ne refl√®tent pas des cas r√©els.
- La complexit√© de certains mod√®les peut ralentir l'ex√©cution.

### **Am√©liorations possibles :**
1. Ajouter des mod√®les suppl√©mentaires (ex. Gradient Boosting, XGBoost).
2. Int√©grer une interface utilisateur pour rendre le pipeline plus interactif.
3. Permettre la mise √† jour des mod√®les directement via Docker.

---

## **Contributeurs**

- **Sidraa93** : Analyse des donn√©es, impl√©mentation des pr√©dictions.  
- **Dineshan12** : D√©veloppement des mod√®les et optimisation.  
- **Collaborateurs** : Dockerisation et documentation.

---

Ce README revisit√© est simple, structur√© et met en avant l'originalit√© du projet. Tu peux le personnaliser selon tes besoins ! üöÄ
